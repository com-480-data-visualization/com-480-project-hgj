{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020 2019 2018 2017 2016 2015]\n"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])\n",
    "years = data['date'].dt.year.unique()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            team       map  CT_total_matches  T_total_matches  CT_wins  \\\n",
      "0    100 Thieves     Dust2               4.0              4.0      2.0   \n",
      "1    100 Thieves   Inferno               4.0              4.0      1.0   \n",
      "2    100 Thieves    Mirage               2.0              2.0      1.0   \n",
      "3    100 Thieves      Nuke               3.0              3.0      2.0   \n",
      "4    100 Thieves     Train               1.0              1.0      0.0   \n",
      "..           ...       ...               ...              ...      ...   \n",
      "175  mousesports     Dust2               2.0              2.0      1.0   \n",
      "176  mousesports   Inferno               2.0              2.0      1.0   \n",
      "177  mousesports    Mirage               4.0              4.0      4.0   \n",
      "178  mousesports  Overpass               2.0              2.0      2.0   \n",
      "179  mousesports     Train               1.0              1.0      0.0   \n",
      "\n",
      "     T_wins  CT_win_rate  T_win_rate  year  \n",
      "0       2.0     0.500000    0.500000  2020  \n",
      "1       2.0     0.250000    0.500000  2020  \n",
      "2       0.0     0.500000    0.000000  2020  \n",
      "3       2.0     0.666667    0.666667  2020  \n",
      "4       0.0     0.000000    0.000000  2020  \n",
      "..      ...          ...         ...   ...  \n",
      "175     1.0     0.500000    0.500000  2015  \n",
      "176     1.0     0.500000    0.500000  2015  \n",
      "177     2.0     1.000000    0.500000  2015  \n",
      "178     2.0     1.000000    1.000000  2015  \n",
      "179     0.0     0.000000    0.000000  2015  \n",
      "\n",
      "[12206 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "all_result = []\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    df_year = data[data['date'].dt.year == year]\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    for index, row in df_year.iterrows():\n",
    "        team1 = row['team_1']\n",
    "        team2 = row['team_2']\n",
    "        map_name = row['_map']\n",
    "        t1_score = row['t_1']\n",
    "        ct2_score = row['ct_2']\n",
    "        ct1_score = row['ct_1']\n",
    "        t2_score = row['t_2']\n",
    "\n",
    "        summary.append([team1, map_name, 'T', t1_score > ct2_score])\n",
    "        summary.append([team2, map_name, 'CT', ct2_score > t1_score])\n",
    "        summary.append([team1, map_name, 'CT', ct1_score > t2_score])\n",
    "        summary.append([team2, map_name, 'T', t2_score > ct1_score])\n",
    "\n",
    "    results_df = pd.DataFrame(summary, columns=['team', 'map', 'side', 'win'])\n",
    "\n",
    "    win_data = results_df.groupby(['team', 'map', 'side']).agg(\n",
    "    total_matches=('win', 'size'),\n",
    "    wins=('win', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    win_data['win_rate'] = win_data['wins'] / win_data['total_matches']\n",
    "\n",
    "    final = win_data.pivot_table(index=['team', 'map'], columns='side', values=['total_matches', 'wins']).reset_index()\n",
    "    final.columns = ['team', 'map', 'CT_total_matches', 'T_total_matches', 'CT_wins', 'T_wins']\n",
    "    final['CT_win_rate'] = final['CT_wins'] / final['CT_total_matches']\n",
    "    final['T_win_rate'] = final['T_wins'] / final['T_total_matches']\n",
    "    final['year'] = year\n",
    "\n",
    "    all_result.append(final)\n",
    "\n",
    "final_results = pd.concat(all_result)\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 86.0\n"
     ]
    }
   ],
   "source": [
    "minimum = final_results['T_total_matches'].min()\n",
    "maximum = final_results['T_total_matches'].max()\n",
    "print(minimum,maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = final_results.to_json(orient='records')\n",
    "\n",
    "with open('data/map_statistics.json', 'w') as f:\n",
    "    f.write(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/picks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              team       map\n",
      "0          TeamOne   Vertigo\n",
      "1          TeamOne     Train\n",
      "2          Recon 5      Nuke\n",
      "3          Recon 5  Overpass\n",
      "4          Rugratz     Dust2\n",
      "...            ...       ...\n",
      "75135  Tempo Storm     Train\n",
      "75136  Tempo Storm   Inferno\n",
      "75137         Envy  Overpass\n",
      "75138         Envy    Mirage\n",
      "75139         Envy     Dust2\n",
      "\n",
      "[75140 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ban_columns = ['t1_removed_1', 't1_removed_2', 't1_removed_3', 't2_removed_1', 't2_removed_2', 't2_removed_3']\n",
    "ban_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    team_1 = row['team_1']\n",
    "    team_2 = row['team_2']\n",
    "    for col in ban_columns[:3]:\n",
    "        if row[col] != '0.0':\n",
    "            ban_data.append({'team': team_1, 'map': row[col]})\n",
    "    for col in ban_columns[3:]:\n",
    "        if row[col] != '0.0':\n",
    "            ban_data.append({'team': team_2, 'map': row[col]})\n",
    "\n",
    "ban_df = pd.DataFrame(ban_data)\n",
    "print(ban_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                team          map  ban_count\n",
      "0        100 Thieves     Overpass         18\n",
      "1        100pinggods         Nuke          1\n",
      "2        100pinggods     Overpass          1\n",
      "3        100pinggods        Train          1\n",
      "4               1337  Cobblestone         17\n",
      "...              ...          ...        ...\n",
      "1871  x6tence Galaxy        Train         30\n",
      "1872             xTc       Mirage          3\n",
      "1873         zARLANS         Nuke         17\n",
      "1874             zzz      Inferno          4\n",
      "1875             zzz       Mirage          4\n",
      "\n",
      "[1876 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guixu\\AppData\\Local\\Temp\\ipykernel_26840\\2993138514.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  most_disliked_maps = ban_counts.groupby('team').apply(find_most_banned_maps).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# counting the number of times each team banned a map \n",
    "ban_counts = ban_df.groupby(['team', 'map']).size().reset_index(name='ban_count')\n",
    "\n",
    "# find most disliked maps\n",
    "def find_most_banned_maps(df):\n",
    "    max_ban_count = df['ban_count'].max()\n",
    "    return df[df['ban_count'] == max_ban_count]\n",
    "\n",
    "most_disliked_maps = ban_counts.groupby('team').apply(find_most_banned_maps).reset_index(drop=True)\n",
    "print(most_disliked_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data in json\n",
    "ban_map = most_disliked_maps.to_json(orient='records')\n",
    "\n",
    "with open('data/most_disliked_maps.json', 'w') as f:\n",
    "    f.write(ban_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overpass' 'Nuke' 'Train' 'Cobblestone' 'Vertigo' 'Cache' 'Dust2'\n",
      " 'Mirage' 'Inferno']\n"
     ]
    }
   ],
   "source": [
    "diffmaps = most_disliked_maps['map'].unique()\n",
    "print(diffmaps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
